{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal:\n",
    "My goal is to take in a dataset containing reviews and create a sentiment analysis model to determine whether those reviews are negative or positive. I will then analyse the model to see how I could improve it.\n",
    "\n",
    "## Steps:\n",
    "This is the method I will be following for this project:\n",
    "1. Load in the data set\n",
    "2. Split the data into training and testing\n",
    "3. Create model\n",
    "4. Train and test the model\n",
    "5. Analyse the results \n",
    "6. Make improvements\n",
    "7. Real-world Applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.0 Importing the data\n",
    "The dataset I will be using in this project is from The University of Michigan who asked their students to review a list of films. I have two datasets here, the training and the testing data. The training data contains a binary feature that denotes if the review was positive or negative. The testing data does not have this feature.\n",
    "\n",
    "I will be importing the csv files as data frames, making sure I separate out the different features by tab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('trainingdata.csv',header=None,sep='\\t',names=['target','text'])\n",
    "test = pd.read_csv('testdata.csv',sep='\\t',header=None,names=['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.0 Splitting the data\n",
    "I will be splitting the 'training' dataset into training and testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = train.drop('target',axis=1)\n",
    "y = train['target']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size = 0.33)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.0 Create the model\n",
    "To create this model I will be using the pipeline feature from sklearn. Within this pipeline I will include a CountVectorizer to clean my input text (getting rid of stopwords and punctuation) and convert it to vector format, TfidfTransformer to add weights to important words, and a MultinomialNB to classify the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Cleaning the text\n",
    "To improve the accuracy of the model I will first create a function that will remove all the stopwords and punctuation from the reviews. Stopwords are words such as: the, when, if, that etc. these words don't tell us anything about the text so they will be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_text(string):\n",
    "    \n",
    "    nopunc = [char for char in string if char not in punctuation]\n",
    "    nopunc = ''.join(nopunc)\n",
    "    \n",
    "    return [word.lower() for word in nopunc if word not in stopwords.words('english')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function will take in a string, remove the punctuation, stopwords and then return the cleaned string."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Creating the pipeline\n",
    "Now it's time to create my pipeline. Within this pipeline I will include 3 elements:\n",
    "1. CountVectorizer.\n",
    "This will convert the strings into a matrix of tokens, whilst also using the function I defined in 3.1 to clean the string.\n",
    "2. TfidfTransformer.\n",
    "This will transform the matrix of tokens into a normalized tf-idf representation. Effectively adding weights to words if they are more important in the corpus.\n",
    "3. MultinomialNB.\n",
    "This is my classifier for my model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('vect',CountVectorizer(analyzer=clean_text)),\n",
    "    ('tfidf',TfidfTransformer()),\n",
    "    ('classifier',MultinomialNB()),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.0 Train and test my model\n",
    "Now that I created my pipeline, it is time to train and test the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer=<function clean_text at 0x102ac7ea0>, binary=False,\n",
       "        decode_error='strict', dtype=<class 'numpy.int64'>,\n",
       "        encoding='utf-8', input='content', lowercase=True, max_df=1.0,\n",
       "        max_features=None, min_df=1, ngram_range=(1, 1), preprocessor=None,\n",
       "...f=False, use_idf=True)), ('classifier', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(x_train.values,y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions_one = pipeline.predict(x_test.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.0 Analyse the results\n",
    "Let's see how our model has performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 544  467]\n",
      " [  56 1216]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.54      0.68      1011\n",
      "          1       0.72      0.96      0.82      1272\n",
      "\n",
      "avg / total       0.80      0.77      0.76      2283\n",
      "\n",
      "\n",
      "\n",
      "Accuracy: 77.0915%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "print(confusion_matrix(y_test.values,predictions_one))\n",
    "print('\\n')\n",
    "print(classification_report(y_test.values,predictions_one))\n",
    "print('\\n')\n",
    "print(\"Accuracy: {:.4%}\".format(np.mean(predictions_one == y_test.values)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a first pass at this model, it's a good set of results. It would appear that our model struggled with precision of positive reviews and the recall of negative reviews. Let's see if we can improve it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.0 Improving the model\n",
    "When using machine learning it is important to always asses and improve the model. To find areas of improvement I will try the following:\n",
    "1. Use GridSearchCV to find optimal parameters\n",
    "2. Use a different classifier in the pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 GridSearchCV with original model\n",
    "To see if I can increase the accuracy of my original model pipeline I will use GridSearchCV to find the optimal parameters I pass through. \n",
    "\n",
    "The parameters that I will be tweaking in this model are the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = {\n",
    "    'vect__ngram_range': [(1,1),(1,2)],\n",
    "    'tfidf__use_idf': (True, False),\n",
    "    'classifier__alpha': (1,1e-1,1e-2,1e-3),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  36 out of  36 | elapsed: 64.8min finished\n"
     ]
    }
   ],
   "source": [
    "gs_clf = GridSearchCV(pipeline, parameters, verbose=1)\n",
    "gs_clf = gs_clf.fit(x_train.values,y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier__alpha': 0.1, 'tfidf__use_idf': True, 'vect__ngram_range': (1, 1)}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The best parameters for my pipeline are the following\n",
    "\n",
    "gs_clf.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_two = gs_clf.predict(x_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 545  466]\n",
      " [  58 1214]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.54      0.68      1011\n",
      "          1       0.72      0.95      0.82      1272\n",
      "\n",
      "avg / total       0.80      0.77      0.76      2283\n",
      "\n",
      "\n",
      "\n",
      "Accuracy: 77.0477%\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test.values,predictions_two))\n",
    "print('\\n')\n",
    "print(classification_report(y_test.values,predictions_two))\n",
    "print('\\n')\n",
    "print(\"Accuracy: {:.4%}\".format(np.mean(predictions_two == y_test.values)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only parameters that it suggested I change was the classifier alpha from 1.0 to 0.1. The accuracy was not increased.\n",
    "\n",
    "### 6.2 Using BernoulliNB\n",
    "\n",
    "Next I will try to use a different classifier, BernoulliNB. From my research I believe that this should improve my results due to it working well on binary features, such as the word vectors in this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('vect',CountVectorizer(analyzer=clean_text)),\n",
    "    ('tfidf',TfidfTransformer()),\n",
    "    ('classifier',BernoulliNB()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer=<function clean_text at 0x102ac7ea0>, binary=False,\n",
       "        decode_error='strict', dtype=<class 'numpy.int64'>,\n",
       "        encoding='utf-8', input='content', lowercase=True, max_df=1.0,\n",
       "        max_features=None, min_df=1, ngram_range=(1, 1), preprocessor=None,\n",
       "..._idf=True)), ('classifier', BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(x_train.values,y_train.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to see if my change of classifier will improve our accuracy results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_three = pipeline.predict(x_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[885 126]\n",
      " [285 987]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.76      0.88      0.81      1011\n",
      "          1       0.89      0.78      0.83      1272\n",
      "\n",
      "avg / total       0.83      0.82      0.82      2283\n",
      "\n",
      "\n",
      "\n",
      "Accuracy: 81.9974%\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test.values,predictions_three))\n",
    "print('\\n')\n",
    "print(classification_report(y_test.values,predictions_three))\n",
    "print('\\n')\n",
    "print(\"Accuracy: {:.4%}\".format(np.mean(predictions_three == y_test.values)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that our accuracy was increased by a few percentage points. What is also interesting about these results is that our model was much more balanced in terms of predicting and recalling both positive and negative reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Final accuracy results\n",
    "Now we have tried our three methods here, the results for accuracy come out as the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BernoulliNB': 0.8199737187910644,\n",
       " 'Multinomial NB after GridSearchCV': 0.77047744196233026,\n",
       " 'MultinomialNB': 0.77091546211125717}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_results = {'MultinomialNB': (np.mean(predictions_one == y_test.values)), 'Multinomial NB after GridSearchCV': (np.mean(predictions_two == y_test.values)), 'BernoulliNB': (np.mean(predictions_three == y_test.values))}\n",
    "acc_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BernoulliNB is clearly the preferred choice.\n",
    "\n",
    "### 6.3.1 Where I could go next\n",
    "There are other areas that I could explore next if I were to continue. I could tweak the parameters even more on both the BernoulliNB and MultinomialNB models, or possibly try other machine learning models away from the Naive Bays package. I could also analyse the predictions to see if there was a trend in the reviews that were misclassified."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.0 Real-world applications\n",
    "This has been an interesting model to work on, but what are the practical applications of a model like this? Here are a couple of areas where I believe we could apply it:\n",
    "\n",
    "1. This model doesn't have to be limited to movie reviews. This could be inbuilt into a chatbot system to determine the sentiment of a conversation between a customer and a customer service representative. \n",
    "2. Internal business communication could be anonymously fed into the model to track the overall mood within the business. If there is a long trend of negative sentiment within the business, this could then be addressed to avoid long term issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
